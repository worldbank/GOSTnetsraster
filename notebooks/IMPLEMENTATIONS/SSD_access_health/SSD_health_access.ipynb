{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating travel time health facilities in South Sudan (SSD); based on damage to facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import rasterio\n",
    "import overturemaps\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import skimage.graph as graph\n",
    "\n",
    "from space2stats_client import Space2StatsClient\n",
    "\n",
    "\n",
    "sys.path.insert(0, r\"C:\\WBG\\Work\\Code\\GOSTrocks\\src\")\n",
    "import GOSTrocks.rasterMisc as rMisc\n",
    "import GOSTrocks.dataMisc as dMisc\n",
    "from GOSTrocks.misc import tPrint, explodeGDF\n",
    "\n",
    "sys.path.append(r\"C:\\WBG\\Work\\Code\\GOSTnetsraster\\src\")\n",
    "import GOSTnetsraster.market_access as ma\n",
    "import GOSTnetsraster.conversion_tables as speed_tables\n",
    "\n",
    "# Initialize the S2S client\n",
    "client = Space2StatsClient(\n",
    "    verify_ssl=False\n",
    ")  # Set verify_ssl=False if you encounter SSL issues\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso3 = \"SSD\"\n",
    "\n",
    "# Input parameters\n",
    "m_crs = 3394  # Need to project data to a metres-based projection\n",
    "\n",
    "# Define input data\n",
    "base_folder = \"C:/WBG/Work/Projects/SSD_Health/\"\n",
    "if not os.path.exists(os.path.join(base_folder, \"DATA\")):\n",
    "    os.makedirs(os.path.join(base_folder, \"DATA\"))\n",
    "\n",
    "landcover_file = os.path.join(base_folder, \"DATA\", \"ESA_Globcover.tif\")\n",
    "transport_network = os.path.join(base_folder, \"DATA\", \"transport_network.gpkg\")\n",
    "major_roads_file = os.path.join(base_folder, \"DATA\", \"major_roads.gpkg\")\n",
    "buildings_file = os.path.join(base_folder, \"DATA\", \"buildings.gpkg\")\n",
    "\n",
    "adm_bounds = dMisc.get_geoboundaries(iso3, \"ADM1\")\n",
    "bbox = list(adm_bounds.total_bounds)\n",
    "\n",
    "# WorldPop 2020 constrained, projected to m_crs\n",
    "pop_file = os.path.join(base_folder, \"DATA\", \"ssd_pop_2025_CN_100m_R2025A_v1.tif\")\n",
    "\n",
    "# administrative boundaries are used to summarize population\n",
    "# adm2 = client.fetch_admin_boundaries(iso3, 'ADM2')\n",
    "# adm1 = client.fetch_admin_boundaries(iso3, 'ADM1')\n",
    "\n",
    "adm1 = dMisc.get_geoboundaries(iso3, \"ADM1\")\n",
    "adm2 = dMisc.get_geoboundaries(iso3, \"ADM2\")\n",
    "\n",
    "# Define project source data\n",
    "source_folder = os.path.join(base_folder, \"DATA\", \"SOURCE\")\n",
    "\n",
    "health_facilities_file = os.path.join(source_folder, \"Health\", \"shapefiles\", \"iraq.shp\")\n",
    "\n",
    "# Define output files\n",
    "friction_folder = os.path.join(base_folder, \"DATA\", \"FRICTION\")\n",
    "results_folder = os.path.join(base_folder, \"RESULTS\")\n",
    "for cFolder in [friction_folder, results_folder]:\n",
    "    if not os.path.exists(cFolder):\n",
    "        os.makedirs(cFolder)\n",
    "friction_file = os.path.join(friction_folder, \"FRICTION.tif\")\n",
    "\n",
    "# Read in data\n",
    "if not os.path.exists(landcover_file):\n",
    "    global_landcover = (\n",
    "        r\"R:\\GLOBAL\\LCVR\\Globcover\\2015\\ESACCI-LC-L4-LCCS-Map-300m-P1Y-2015-v2.0.7.tif\"\n",
    "    )\n",
    "    in_lc = rasterio.open(global_landcover)\n",
    "    temp_landcover_file = landcover_file.replace(\".tif\", \"_temp.tif\")\n",
    "    if not os.path.exists(temp_landcover_file):\n",
    "        local_lc = rMisc.clipRaster(in_lc, adm_bounds, temp_landcover_file)\n",
    "    temp_lc = rasterio.open(temp_landcover_file)\n",
    "    proj_res = rMisc.project_raster(temp_lc, m_crs)\n",
    "    with rasterio.open(landcover_file, \"w\", **proj_res[1]) as outR:\n",
    "        outR.write(proj_res[0])\n",
    "\n",
    "in_lc = rasterio.open(landcover_file)\n",
    "in_pop = rasterio.open(pop_file)\n",
    "if in_pop.crs != in_lc.crs:\n",
    "    proj_res = rMisc.standardizeInputRasters(\n",
    "        in_pop, in_lc, pop_file.replace(\".tif\", \"_proj.tif\")\n",
    "    )\n",
    "\n",
    "in_pop = rasterio.open(pop_file.replace(\".tif\", \"_proj.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SMOD and UCDB datasets\n",
    "smod_path = r\"C:\\WBG\\Work\\data\\URBAN\\GHS_SMOD_E2030_GLOBE_R2023A_54009_1000_V1_0.tif\"\n",
    "out_folder = os.path.join(base_folder, \"URBAN\")\n",
    "out_smod = os.path.join(out_folder, \"smod_2020.tif\")\n",
    "out_ucdb = os.path.join(out_folder, \"ucdb_2024.gpkg\")\n",
    "out_ucdb_big = os.path.join(out_folder, \"ucdb_2024_gt1000000.gpkg\")\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "\n",
    "if not os.path.exists(out_smod):\n",
    "    smod = rMisc.clipRaster(rasterio.open(smod_path), adm_bounds, out_smod)\n",
    "\n",
    "if not os.path.exists(out_ucdb):\n",
    "    good_ucdb_cols = [\"ID_UC_G0\", \"GC_POP_TOT_2025\", \"geometry\"]\n",
    "    ucdb_file = r\"C:\\WBG\\Work\\data\\URBAN\\GHS_UCDB_GLOBE_R2024A.gpkg\"\n",
    "    ucdb = gpd.read_file(ucdb_file, layer=\"GHS_UCDB_THEME_SOCIOECONOMIC_GLOBE_R2024A\")\n",
    "    admin_bounds_crs = adm_bounds.to_crs(ucdb.crs)\n",
    "    matching_ucdb = gpd.sjoin(\n",
    "        ucdb, admin_bounds_crs, how=\"inner\", predicate=\"intersects\"\n",
    "    )\n",
    "    matching_ucdb.loc[:, good_ucdb_cols].to_file(\n",
    "        out_ucdb, driver=\"GPKG\", layer=\"ucdb_2024\", index=False\n",
    "    )\n",
    "\n",
    "if not os.path.exists(out_ucdb_big):\n",
    "    matching_ucdb = gpd.read_file(out_ucdb)\n",
    "    matching_ucdb_big = matching_ucdb[matching_ucdb[\"GC_POP_TOT_2025\"] > 1000000]\n",
    "    matching_ucdb_big.to_file(\n",
    "        out_ucdb_big, driver=\"GPKG\", layer=\"ucdb_2024_gt1000000\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download roads from Overture\n",
    "# Download transport network\n",
    "if not os.path.exists(transport_network):\n",
    "    transport = overturemaps.record_batch_reader(\"segment\", bbox).read_all()\n",
    "    transport_df = gpd.GeoDataFrame.from_arrow(transport)\n",
    "    transport_df.crs = 4326\n",
    "    transport_df.loc[\n",
    "        :,\n",
    "        [\n",
    "            \"id\",\n",
    "            \"class\",\n",
    "            \"subtype\",\n",
    "            \"road_surface\",\n",
    "            \"speed_limits\",\n",
    "            \"width_rules\",\n",
    "            \"geometry\",\n",
    "        ],\n",
    "    ].to_file(transport_network, driver=\"GPKG\")\n",
    "\n",
    "# process transport to a) remove roads outside IRAQ and b) remove all roads of OSMLR class 3 and 4\n",
    "if not os.path.exists(major_roads_file):\n",
    "    roads = gpd.read_file(transport_network)\n",
    "    roads[\"OSMLR_class\"] = roads[\"class\"].map(speed_tables.OSMLR_Classes)\n",
    "    roads_joined = gpd.sjoin(roads, adm_bounds, how=\"inner\", predicate=\"intersects\")\n",
    "    major_roads = roads_joined.loc[\n",
    "        roads_joined[\"OSMLR_class\"].isin([\"OSMLR level 1\", \"OSMLR level 2\"]),\n",
    "        roads.columns,\n",
    "    ]\n",
    "    major_roads.to_file(\n",
    "        major_roads_file, driver=\"GPKG\", layer=\"major_roads\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_roads = gpd.read_file(transport_network)\n",
    "all_roads[\"speed\"] = all_roads[\"class\"].map(speed_tables.osm_speed_dict)\n",
    "all_roads[\"speed\"] = all_roads[\"speed\"].fillna(10.0)\n",
    "\n",
    "lc_speed_table = speed_tables.esaacci_landcover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate friction surface\n",
    "if not os.path.exists(friction_file):\n",
    "    pre_roads = all_roads.copy()\n",
    "    pre_friction = ma.generate_roads_lc_friction(\n",
    "        in_lc,\n",
    "        pre_roads,\n",
    "        lc_travel_table=lc_speed_table,\n",
    "        out_file=friction_file,\n",
    "        resolution=in_lc.res[0],\n",
    "    )\n",
    "friction = rasterio.open(friction_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate travel time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate travel time to major cities\n",
    "tt_folder = os.path.join(results_folder, \"TRAVEL_TIME\")\n",
    "admin_results_folder = os.path.join(results_folder, \"ADMIN_1_SUMMARIES\")\n",
    "if not os.path.exists(admin_results_folder):\n",
    "    os.makedirs(admin_results_folder)\n",
    "\n",
    "for dests_file, label in [\n",
    "    [out_ucdb_big, \"major-cities\"],\n",
    "    [out_ucdb, \"cities\"],\n",
    "    [industrial_zones_file, \"industrial-zones\"],\n",
    "    [airports_file, \"airports\"],\n",
    "    [border_crossings_file, \"border-crossings\"],\n",
    "    [health_facilities_file, \"health-facilities\"],\n",
    "    [unesco_file, \"unesco\"],\n",
    "    [tourism_file, \"tourism\"],\n",
    "]:\n",
    "    tPrint(f\"Calculating travel time to {label}...\")\n",
    "    dests = explodeGDF(gpd.read_file(dests_file))\n",
    "    dests = dests.to_crs(m_crs)\n",
    "    if dests[\"geometry\"].iloc[0].geom_type != \"Point\":\n",
    "        dests[\"geometry\"] = dests[\"geometry\"].apply(lambda x: x.centroid)\n",
    "\n",
    "    frictionD = post_friction.read()[0, :, :]\n",
    "    frictionD = frictionD * post_friction.res[0]\n",
    "    mcp = graph.MCP_Geometric(frictionD)\n",
    "    # ma.calculate_travel_time(post_friction, mcp, dests, out_raster=os.path.join(tt_folder, f\"tt_{label}_post.tif\"))\n",
    "    post_tt = ma.summarize_travel_time_populations(\n",
    "        in_pop,\n",
    "        post_friction,\n",
    "        dests,\n",
    "        mcp,\n",
    "        adm_bounds,\n",
    "        out_tt_file=os.path.join(tt_folder, f\"tt_{label}_post.tif\"),\n",
    "    )\n",
    "    pd.DataFrame(post_tt.drop([\"geometry\"], axis=1)).to_csv(\n",
    "        os.path.join(admin_results_folder, f\"POST_ADM2_tt_{label}.csv\")\n",
    "    )\n",
    "\n",
    "    frictionD = pre_friction.read()[0, :, :]\n",
    "    frictionD = frictionD * pre_friction.res[0]\n",
    "    mcp = graph.MCP_Geometric(frictionD)\n",
    "    # ma.calculate_travel_time(pre_friction, mcp, dests, out_raster=os.path.join(tt_folder, f\"tt_{label}_pre.tif\"))\n",
    "    pre_tt = ma.summarize_travel_time_populations(\n",
    "        in_pop,\n",
    "        pre_friction,\n",
    "        dests,\n",
    "        mcp,\n",
    "        adm_bounds,\n",
    "        out_tt_file=os.path.join(tt_folder, f\"tt_{label}_pre.tif\"),\n",
    "    )\n",
    "    pd.DataFrame(pre_tt.drop([\"geometry\"], axis=1)).to_csv(\n",
    "        os.path.join(admin_results_folder, f\"PRE_ADM2_tt_{label}.csv\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(os.path.join(results_folder, \"combined_travel_time_adm1.csv\"))\n",
    "except:\n",
    "    pass\n",
    "# Aggregate admin summary results\n",
    "results_files = [\n",
    "    os.path.join(admin_results_folder, x)\n",
    "    for x in os.listdir(admin_results_folder)\n",
    "    if x.endswith(\".csv\")\n",
    "]\n",
    "all_res = []\n",
    "for result_file in results_files:\n",
    "    dest = os.path.basename(result_file).split(\"_\")[-1][:-4]\n",
    "    time = os.path.basename(result_file).split(\"_\")[0]\n",
    "    tPrint(f\"{dest} {time}\")\n",
    "    res = pd.read_csv(result_file, index_col=0)\n",
    "    res = res.loc[:, [\"shapeName\", \"shapeID\", \"tt_pop_w\"]]\n",
    "    res = res.rename(columns={\"tt_pop_w\": f\"tt_pop_{dest}_{time}\"})\n",
    "    all_res.append(res)\n",
    "\n",
    "combo_res = pd.concat(all_res, axis=1)\n",
    "combo_res.T.drop_duplicates().T.sort_index(axis=1).to_csv(\n",
    "    os.path.join(results_folder, \"combined_travel_time_adm1.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access to industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tt_rasters = [\n",
    "    os.path.join(tt_folder, x) for x in os.listdir(tt_folder) if x.endswith(\".tif\")\n",
    "]\n",
    "# Buffer the industrial zones and summarize travel time within\n",
    "industrial_zones = gpd.read_file(industrial_zones_file)\n",
    "industrial_zones = industrial_zones.to_crs(m_crs)\n",
    "industrial_res = industrial_zones.copy()\n",
    "for buffer in [1000, 2500, 5000, 10000]:\n",
    "    buffered_zones = industrial_zones.copy()\n",
    "    buffered_zones[\"geometry\"] = buffered_zones[\"geometry\"].buffer(buffer)\n",
    "    total_pop = rMisc.zonalStats(buffered_zones, in_pop, minVal=0, return_df=True)\n",
    "    industrial_res[f\"pop_{buffer}_sum\"] = total_pop[\"SUM\"].values\n",
    "    for tt_raster in all_tt_rasters:\n",
    "        tt_label = os.path.basename(tt_raster).split(\"_\")[1]\n",
    "        time_label = os.path.basename(tt_raster).split(\"_\")[-1][:-4]\n",
    "        tPrint(\n",
    "            f\"Summarizing {time_label} {tt_label} travel time within {buffer}m of industrial zones...\"\n",
    "        )\n",
    "        res = rMisc.zonalStats(buffered_zones, tt_raster, return_df=True)\n",
    "        industrial_res[f\"tt_{time_label}_{tt_label}_{buffer}_mean\"] = res[\"MEAN\"]\n",
    "        industrial_res[f\"tt_{time_label}_{tt_label}_{buffer}_max\"] = res[\"MAX\"]\n",
    "\n",
    "industrial_res.drop([\"geometry\"], axis=1).to_csv(\n",
    "    os.path.join(results_folder, \"industrial_zones_travel_time.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access to health care facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buffer proposed roads and summarize travel time within\n",
    "proposed_roads = gpd.read_file(road_segments_file)\n",
    "proposed_roads = proposed_roads.to_crs(m_crs)\n",
    "proposed_roads = proposed_roads.dissolve(by=\"Section\")\n",
    "proposed_roads.union_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for buffer in [1000, 2500, 5000, 10000]:\n",
    "    buffered_roads = proposed_roads.copy()\n",
    "    buffered_roads[\"geometry\"] = buffered_roads[\"geometry\"].buffer(buffer)\n",
    "    total_pop = rMisc.zonalStats(buffered_roads, in_pop, minVal=0, return_df=True)\n",
    "    proposed_roads[f\"pop_{buffer}_sum\"] = total_pop[\"SUM\"].values\n",
    "    for tt_raster in all_tt_rasters:\n",
    "        tt_label = os.path.basename(tt_raster).split(\"_\")[1]\n",
    "        time_label = os.path.basename(tt_raster).split(\"_\")[-1][:-4]\n",
    "        tPrint(\n",
    "            f\"Summarizing {time_label} {tt_label} travel time within {buffer}m of proposed roads...\"\n",
    "        )\n",
    "        res = rMisc.zonalStats(buffered_roads, tt_raster, return_df=True)\n",
    "        proposed_roads[f\"tt_{time_label}_{tt_label}_{buffer}_mean\"] = res[\"MEAN\"].values\n",
    "        proposed_roads[f\"tt_{time_label}_{tt_label}_{buffer}_max\"] = res[\"MAX\"].values\n",
    "proposed_roads.drop([\"geometry\"], axis=1).to_csv(\n",
    "    os.path.join(results_folder, \"proposed_roads_travel_time.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tourism access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unesco_sites = gpd.read_file(unesco_file)\n",
    "unesco_sites = unesco_sites.to_crs(m_crs)\n",
    "tourism_sites = gpd.read_file(tourism_file)\n",
    "tourism_sites = tourism_sites.to_crs(m_crs)\n",
    "all_tourism = pd.concat([unesco_sites, tourism_sites], ignore_index=True)\n",
    "\n",
    "for buffer in [1000, 2500, 5000, 10000]:\n",
    "    buffered_tourism = all_tourism.copy()\n",
    "    buffered_tourism[\"geometry\"] = buffered_tourism[\"geometry\"].buffer(buffer)\n",
    "    total_pop = rMisc.zonalStats(buffered_tourism, in_pop, minVal=0, return_df=True)\n",
    "    buffered_tourism[f\"pop_{buffer}_sum\"] = total_pop[\"SUM\"].values\n",
    "    for tt_raster in all_tt_rasters:\n",
    "        tt_label = os.path.basename(tt_raster).split(\"_\")[1]\n",
    "        time_label = os.path.basename(tt_raster).split(\"_\")[-1][:-4]\n",
    "        tPrint(\n",
    "            f\"Summarizing {time_label} {tt_label} travel time within {buffer}m of tourism sites...\"\n",
    "        )\n",
    "        res = rMisc.zonalStats(buffered_tourism, tt_raster, return_df=True)\n",
    "        buffered_tourism[f\"tt_{time_label}_{tt_label}_{buffer}_mean\"] = res[\n",
    "            \"MEAN\"\n",
    "        ].values\n",
    "        buffered_tourism[f\"tt_{time_label}_{tt_label}_{buffer}_max\"] = res[\"MAX\"].values\n",
    "\n",
    "buffered_tourism.drop([\"geometry\"], axis=1).to_csv(\n",
    "    os.path.join(results_folder, \"tourism_travel_time.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = gpd.read_file(out_ucdb)\n",
    "cities.sort_values(\"GC_POP_TOT_2025\", ascending=False, inplace=True)\n",
    "\"\"\"cities.drop_duplicates(subset=['ID_UC_G0'], keep='first', inplace=True)\n",
    "cities.to_file(out_ucdb, driver=\"GPKG\", layer=\"ucdb_2024\", index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "cities.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gostnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
